{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referred from https://gaussian37.github.io/dl-concept-focal_loss/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss for sementic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Time dimension: from B, C, H, W -> B, T, C, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "def label_to_one_hot_label(\n",
    "    labels: torch.Tensor,\n",
    "    num_classes: int,\n",
    "    device: Optional[torch.device] = None,\n",
    "    dtype: Optional[torch.dtype] = None,\n",
    "    eps: float = 1e-6,\n",
    "    ignore_index=255,\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Convert an integer label x-D tensor to a one-hot (x+1)-D tensor.\n",
    "\n",
    "    Args:\n",
    "        labels: tensor with labels of shape :math:`(N, *)`, where N is batch size.\n",
    "          Each value is an integer representing correct classification.\n",
    "        num_classes: number of classes in labels.\n",
    "        device: the desired device of returned tensor.\n",
    "        dtype: the desired data type of returned tensor.\n",
    "\n",
    "    Returns:\n",
    "        the labels in one hot tensor of shape :math:`(N, C, *)`,\n",
    "\n",
    "    Examples:\n",
    "        >>> labels = torch.LongTensor([\n",
    "                [[0, 1], \n",
    "                [2, 0]]\n",
    "            ])\n",
    "        >>> one_hot(labels, num_classes=3)\n",
    "        tensor([[[[1.0000e+00, 1.0000e-06],\n",
    "                  [1.0000e-06, 1.0000e+00]],\n",
    "        \n",
    "                 [[1.0000e-06, 1.0000e+00],\n",
    "                  [1.0000e-06, 1.0000e-06]],\n",
    "        \n",
    "                 [[1.0000e-06, 1.0000e-06],\n",
    "                  [1.0000e+00, 1.0000e-06]]]])\n",
    "\n",
    "    \"\"\"\n",
    "    shape = labels.shape\n",
    "    # one hot : (B, C=ignore_index+1, H, W)\n",
    "    one_hot = torch.zeros((shape[0], ignore_index+1) + shape[1:], device=device, dtype=dtype)\n",
    "    \n",
    "    # labels : (B, H, W)\n",
    "    # labels.unsqueeze(1) : (B, C=1, H, W)\n",
    "    # one_hot : (B, C=ignore_index+1, H, W)\n",
    "    one_hot = one_hot.scatter_(1, labels.unsqueeze(1), 1.0) + eps\n",
    "    \n",
    "    # ret : (B, C=num_classes, H, W)\n",
    "    ret = torch.split(one_hot, [num_classes, ignore_index+1-num_classes], dim=1)[0]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "# https://github.com/zhezh/focalloss/blob/master/focalloss.py\n",
    "def focal_loss(input, target, alpha, gamma, reduction, eps, ignore_index):\n",
    "    \n",
    "    r\"\"\"Criterion that computes Focal loss.\n",
    "\n",
    "    According to :cite:`lin2018focal`, the Focal loss is computed as follows:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)\n",
    "\n",
    "    Where:\n",
    "       - :math:`p_t` is the model's estimated probability for each class.\n",
    "\n",
    "    Args:\n",
    "        input: logits tensor with shape :math:`(N, C, *)` where C = number of classes.\n",
    "        target: labels tensor with shape :math:`(N, *)` where each value is :math:`0 ≤ targets[i] ≤ C−1`.\n",
    "        alpha: Weighting factor :math:`\\alpha \\in [0, 1]`.\n",
    "        gamma: Focusing parameter :math:`\\gamma >= 0`.\n",
    "        reduction: Specifies the reduction to apply to the\n",
    "          output: ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n",
    "          will be applied, ``'mean'``: the sum of the output will be divided by\n",
    "          the number of elements in the output, ``'sum'``: the output will be\n",
    "          summed.\n",
    "        eps: Scalar to enforce numerical stabiliy.\n",
    "\n",
    "    Return:\n",
    "        the computed loss.\n",
    "\n",
    "    Example:\n",
    "        >>> N = 5  # num_classes\n",
    "        >>> input = torch.randn(1, N, 3, 5, requires_grad=True)\n",
    "        >>> target = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
    "        >>> output = focal_loss(input, target, alpha=0.5, gamma=2.0, reduction='mean')\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "    if not isinstance(input, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(input)}\")\n",
    "\n",
    "    if not len(input.shape) >= 2:\n",
    "        raise ValueError(f\"Invalid input shape, we expect BxCx*. Got: {input.shape}\")\n",
    "\n",
    "    if input.size(0) != target.size(0):\n",
    "        raise ValueError(f'Expected input batch_size ({input.size(0)}) to match target batch_size ({target.size(0)}).')\n",
    "\n",
    "    # input : (B, C, H, W) -> (B, bin, T, H, W)\n",
    "    n = input.size(0) # B\n",
    "    \n",
    "    # out_sie : (B, H, W) -> (B, T, H, W)\n",
    "    out_size = input.size()[0:1] + input.size()[3:]\n",
    "    \n",
    "    # input : (B, C, H, W) -> (B, bin, T, H, W)\n",
    "    # target : (B, H, W) -> (B, T, H, W)\n",
    "    if target.size()[1:] != input.size()[2:]:\n",
    "        raise ValueError(f'Expected target size {out_size}, got {target.size()}')\n",
    "\n",
    "    if not input.device == target.device:\n",
    "        raise ValueError(f\"input and target must be in the same device. Got: {input.device} and {target.device}\")\n",
    "    \n",
    "    if isinstance(alpha, float):\n",
    "        pass\n",
    "    elif isinstance(alpha, np.ndarray):\n",
    "        alpha = torch.from_numpy(alpha)\n",
    "        # alpha : (B, C, H, W)\n",
    "        alpha = alpha.view(-1, len(alpha), 1, 1).expand_as(input)\n",
    "    elif isinstance(alpha, torch.Tensor):\n",
    "        # alpha : (B, C, H, W)\n",
    "        alpha = alpha.view(-1, len(alpha), 1, 1).expand_as(input)       \n",
    "        \n",
    "\n",
    "    # compute softmax over the classes axis\n",
    "    # input_soft : (B, C, H, W) -> (B, C, T, H, W)\n",
    "    input_soft = F.softmax(input, dim=1) + eps\n",
    "    \n",
    "    # create the labels one hot tensor\n",
    "    # target_one_hot : (B, C, H, W) -> (B, C, T, H, W)\n",
    "    target_one_hot = label_to_one_hot_label(target.long(), num_classes=input.shape[1], device=input.device, dtype=input.dtype, ignore_index=ignore_index)\n",
    "    print(\"target_one_hot shape \", target_one_hot.shape)\n",
    "\n",
    "    # compute the actual focal loss\n",
    "    weight = torch.pow(1.0 - input_soft, gamma)\n",
    "    \n",
    "    # alpha, weight, input_soft : (B, C, H, W)\n",
    "    # focal : (B, C, H, W)\n",
    "    focal = -alpha * weight * torch.log(input_soft)\n",
    "    \n",
    "    # loss_tmp : (B, H, W)\n",
    "    loss_tmp = torch.sum(target_one_hot * focal, dim=1)\n",
    "\n",
    "    if reduction == 'none':\n",
    "        # loss : (B, H, W)\n",
    "        loss = loss_tmp\n",
    "    elif reduction == 'mean':\n",
    "        # loss : scalar\n",
    "        loss = torch.mean(loss_tmp)\n",
    "    elif reduction == 'sum':\n",
    "        # loss : scalar\n",
    "        loss = torch.sum(loss_tmp)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Invalid reduction mode: {reduction}\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    r\"\"\"Criterion that computes Focal loss.\n",
    "\n",
    "    According to :cite:`lin2018focal`, the Focal loss is computed as follows:\n",
    "\n",
    "    .. math:\n",
    "\n",
    "        FL(p_t) = -alpha_t(1 - p_t)^{gamma}, log(p_t)\n",
    "\n",
    "    Where:\n",
    "       - :math:`p_t` is the model's estimated probability for each class.\n",
    "\n",
    "    Args:\n",
    "        alpha: Weighting factor :math:`\\alpha \\in [0, 1]`.\n",
    "        gamma: Focusing parameter :math:`\\gamma >= 0`.\n",
    "        reduction: Specifies the reduction to apply to the\n",
    "          output: ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n",
    "          will be applied, ``'mean'``: the sum of the output will be divided by\n",
    "          the number of elements in the output, ``'sum'``: the output will be\n",
    "          summed.\n",
    "        eps: Scalar to enforce numerical stabiliy.\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, *)` where C = number of classes.\n",
    "        - Target: :math:`(N, *)` where each value is\n",
    "          :math:`0 ≤ targets[i] ≤ C−1`.\n",
    "\n",
    "    Example:\n",
    "        >>> N = 5  # num_classes\n",
    "        >>> kwargs = {\"alpha\": 0.5, \"gamma\": 2.0, \"reduction\": 'mean'}\n",
    "        >>> criterion = FocalLoss(**kwargs)\n",
    "        >>> input = torch.randn(1, N, 3, 5, requires_grad=True)\n",
    "        >>> target = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
    "        >>> output = criterion(input, target)\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, gamma = 2.0, reduction = 'mean', eps = 1e-8, ignore_index=30):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return focal_loss(input, target, self.alpha, self.gamma, self.reduction, self.eps, self.ignore_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_one_hot shape  torch.Size([1, 2, 32, 252, 252])\n"
     ]
    }
   ],
   "source": [
    "N = 2 # numclasses\n",
    "kwargs = {\"alpha\": 0.2, \"gamma\": 2.0, \"reduction\": 'mean'}\n",
    "criterion = FocalLoss(**kwargs)\n",
    "input = torch.randn(1, N, 32, 252, 252, requires_grad=True)\n",
    "target = torch.empty(1, 32, 252, 252, dtype=torch.long).random_(N)\n",
    "output = criterion(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "torch.Size([1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.LongTensor([\n",
    "                [[0, 1], \n",
    "                [2, 0]]\n",
    "            ])\n",
    "print(labels.shape)\n",
    "one_hot = torch.Tensor([[[[1.0000e+00, 1.0000e-06],\n",
    "                  [1.0000e-06, 1.0000e+00]],\n",
    "        \n",
    "                 [[1.0000e-06, 1.0000e+00],\n",
    "                  [1.0000e-06, 1.0000e-06]],\n",
    "        \n",
    "                 [[1.0000e-06, 1.0000e-06],\n",
    "                  [1.0000e+00, 1.0000e-06]]]])\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "  def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "      super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "      self.gamma = gamma\n",
    "      self.weight = torch.FloatTensor([0.15, 0.85]) #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "  def forward(self, input, target):\n",
    "      # print(input.dtype, target.dtype, self.weight.dtype)\n",
    "      ce_loss = F.cross_entropy(input, target.long(),reduction=self.reduction,weight=self.weight)\n",
    "      pt = torch.exp(-ce_loss)\n",
    "      focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "      return focal_loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b183ca1800ea4e96dc3b796f78e5d640ebd4e2c7ed81e2a7c90e09c6123cdf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('LTML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
